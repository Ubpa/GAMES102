{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    \"\"\"\n",
    "    导入数据\n",
    "    input:  file_name(string):文件的存储位置\n",
    "    output: samples(mat):特征\n",
    "            labels(mat):标签\n",
    "            n_class(int):类别的个数\n",
    "    \"\"\"\n",
    "    # 1. 获取特征\n",
    "    f = open(file_name)\n",
    "    samples = []\n",
    "    labels = []\n",
    "    for line in f.readlines():\n",
    "        samples_tmp = []\n",
    "        lines = line.strip().split(\"\\t\")\n",
    "        for i in range(len(lines) - 1):\n",
    "            samples_tmp.append(float(lines[i]))  # 从字符串转为浮点型\n",
    "        labels.append(int(lines[-1]))\n",
    "        samples.append(samples_tmp)\n",
    "    f.close()\n",
    "    n_class = 1\n",
    "    \n",
    "    return mat(samples), mat(labels).transpose(), n_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 训练网络模型\n",
    "## 2.1 正向传播\n",
    "### 2.1.1 计算隐含层的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_out(samples, center, rbf_delta):\n",
    "    \"\"\"\n",
    "    rbf函数（隐含层神经元输出函数）\n",
    "    input:samples(mat):数据特征\n",
    "          center(mat):rbf函数中心\n",
    "          rbf_delta(mat)：rbf函数扩展常数\n",
    "    output：hidden_output（mat）隐含层输出\n",
    "    \"\"\"\n",
    "    n_sample, n_feature = shape(samples)\n",
    "    n_hidden, n_hidden_value = shape(center)  # (隐含层节点数, 隐含层节点对sample的每个feature的值的数量=n_feature)\n",
    "    \n",
    "    # 每个样本要和隐含层的每个节点做一次运算\n",
    "    hidden_output = mat(zeros((n_sample, n_hidden)))  # 每一行的信息是一个样本的所有特征和每个隐含层节点的运算值\n",
    "    for i in range(n_sample):\n",
    "        for j in range(n_hidden):\n",
    "            hidden_output[i, j] = exp(\n",
    "                -1.0 * (samples[i,:] - center[j,:]) * (samples[i,:] - center[j,:]).T /\n",
    "                (2 * rbf_delta[0,j] * rbf_delta[0,j])\n",
    "            )  # 高斯核函数\n",
    "            \n",
    "    return hidden_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 计算输出层的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_in(hidden_output, w):\n",
    "    \"\"\"\n",
    "    计算输出层的输入\n",
    "    input:  hidden_output(mat):隐含层的输出\n",
    "            w(mat):隐含层到输出层之间的权重\n",
    "    output: predict_in(mat):输出层的输入  (样本数, 输出节点数) 每一行的信息是样本的每个输出的预测值\n",
    "    \"\"\"\n",
    "    predict_in = hidden_output * w\n",
    "    return predict_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 集散输出层的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x):\n",
    "    \"\"\"\n",
    "    输出层神经元激活函数\n",
    "    input:  x(mat/float):自变量，可以是矩阵或者是任意实数\n",
    "    output: 这里采用的是线性函数 y=x\n",
    "    \"\"\"\n",
    "    return x\n",
    "\n",
    "def predict_out(predict_in):\n",
    "    \"\"\"\n",
    "    输出层的输出\n",
    "    input:  predict_in(mat):输出层的输入\n",
    "    output: result(mat):输出层的输出\n",
    "    \"\"\"\n",
    "    result = linear(predict_in)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 误差的反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp(samples, label, predict, center, rbf_delta, w, alpha):\n",
    "    \"\"\"\n",
    "    input:  label:真实值\n",
    "            output_out:预测值\n",
    "            center(mat):rbf函数中心\n",
    "            rbf_delta(mat)：rbf函数扩展常数\n",
    "            w(mat):隐含层到输出层之间的权重\n",
    "            alpha:学习率\n",
    "    \"\"\"\n",
    "    n_hidden, _ = shape(center)\n",
    "    n_sample, _ = shape(samples)\n",
    "    error = mat(label - predict)  # 每一行的信息是一个样本的每个预测输出的误差\n",
    "    # 梯度下降之计算梯度\n",
    "    for j in range(n_hidden):\n",
    "        sum1 = 0.0\n",
    "        sum2 = 0.0\n",
    "        sum3 = 0.0\n",
    "        for i in range(n_sample):\n",
    "            sum1 += error[i,:] * exp(-1.0 * (samples[i,:]-center[j,:]) * (samples[i,:]-center[j,:]).T / (2 * rbf_delta[0,j] * rbf_delta[0,j])) * (samples[i,:]-center[j,:])\n",
    "            sum2 += error[i,:] * exp(-1.0 * (samples[i,:]-center[j,:]) * (samples[i,:]-center[j,:]).T / (2 * rbf_delta[0,j] * rbf_delta[0,j])) * (samples[i,:]-center[j,:]) * (samples[i,:]-center[j,:]).T\n",
    "            sum3 += error[i,:] * exp(-1.0 * (samples[i,:]-center[j,:]) * (samples[i,:]-center[j,:]).T / (2 * rbf_delta[0,j] * rbf_delta[0,j]))\n",
    "        # 得梯度\n",
    "        delta_center    = (w[j,:] / (rbf_delta[0,j] * rbf_delta[0,j])) * sum1\n",
    "        delta_rbf_delta = (w[j,:] / (rbf_delta[0,j] * rbf_delta[0,j] * rbf_delta[0,j])) * sum2\n",
    "        delta_w = sum3\n",
    "        \n",
    "        # 学习 根据梯度修正权重和rbf函数中心和扩展常数 \n",
    "        center[j,:] = center[j,:] - alpha * delta_center  # ?\n",
    "        rbf_delta[0,j] = rbf_delta[0,j] - alpha * delta_rbf_delta\n",
    "        w[j,:] = w[j,:] - alpha * delta_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1~2.2 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_train(samples, labels, n_hidden, maxIteration, alpha, n_output):\n",
    "    \"\"\"\n",
    "    计算隐含层的输入\n",
    "    input:  samples(mat):数据特征\n",
    "            labels(mat):标签\n",
    "            n_hidden(int):隐含层的节点个数\n",
    "            maxIteration(int):最大的迭代次数\n",
    "            alpha(float):学习率\n",
    "            n_output(int):输出层的节点个数\n",
    "    output: center(mat):rbf函数中心\n",
    "            rbf_delta(mat):rbf函数扩展常数\n",
    "            w(mat):隐含层到输出层之间的权重\n",
    "    \"\"\"\n",
    "    n_sample, n_feature = shape(samples)  # m为样本数, n为特征数\n",
    "    \n",
    "    ## 初始化参数 ##\n",
    "    center = mat(random.rand(n_hidden, n_feature))  # (隐含层节点数, 样本特征数) rand的范围在0~1之间\n",
    "    center = center * (8.0 * sqrt(6) / sqrt(n_feature + n_hidden)) - mat(ones((n_hidden, n_feature))) * (4.0 * sqrt(6) / sqrt(n_feature + n_hidden))  # 使初始化的参数落在一个更好的区间中, ?具体为什么8*sqrt(6)还没搞懂\n",
    "    rbf_delta = mat(random.rand(1, n_hidden))  # (1, 隐含层节点数) \n",
    "    rbf_delta = rbf_delta * (8.0 * sqrt(6) / sqrt(n_feature + n_hidden)) - mat(ones((1, n_hidden))) * (4.0 * sqrt(6) / sqrt(n_feature + n_hidden))\n",
    "    w = mat(random.rand(n_hidden, n_output))  # (隐含层节点数, 输出节点数)\n",
    "    w = w * (8.0 * sqrt(6) / sqrt(n_hidden + n_output)) - mat(ones((n_hidden, n_output))) * (4.0 * sqrt(6) / sqrt(n_hidden + n_output))\n",
    "    \n",
    "    ## 训练 ##\n",
    "    iter = 0\n",
    "    while iter <= maxIteration:\n",
    "        # 2.1 正向传播\n",
    "        # 2.1.1 计算隐含层的输出\n",
    "        hidden_output = hidden_out(samples, center, rbf_delta)  # 得到每个样本和每个隐含层节点运算的结果\n",
    "        # 2.1.2 计算输出层的输入\n",
    "        output_in = predict_in(hidden_output, w)\n",
    "        # 2.1.3 集散输出层的输出, 激活\n",
    "        predict = predict_out(output_in)\n",
    "        \n",
    "        # 2.2 反向传播\n",
    "        bp(samples, label, predict, center, rbf_delta, w, alpha)  # 传的是引用(传可变对象进去, 就是传引用)\n",
    "        \n",
    "        if iter % 10 == 0:\n",
    "            cost = get_cost(get_predict(samples, center, rbf_delta, w) - label)\n",
    "            print (\"\\t-------- iter: \", iter, \" ,cost: \",  cost)\n",
    "        if cost < 3:   ###如果损失函数值小于3则停止迭\n",
    "            break\n",
    "        iter += 1\n",
    "    \n",
    "    return center, rbf_delta, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(cost):\n",
    "    \"\"\"\n",
    "    计算当前损失函数的值: 欧氏距离?\n",
    "    input:  cost(mat):预测值与标签之间的差\n",
    "    output: cost_sum / m (double):损失函数的值\n",
    "    \"\"\"\n",
    "    n_sample, n_predict_output = shape(cost)\n",
    "    \n",
    "    cost_sum = 0.0\n",
    "    for i in range(n_sample):\n",
    "        for j in range(n_predict_output):\n",
    "            cost_sum += cost[i,j] * cost[i,j]\n",
    "    return cost_sum / 2\n",
    "\n",
    "def get_predict(samples, center, rbf_delta, w):\n",
    "    \"\"\"\n",
    "    计算最终的预测\n",
    "    input:  samples(mat):特征\n",
    "    output: 预测值\n",
    "    \"\"\"\n",
    "    return predict_out(predict_in(hidden_out(samples, center, rbf_delta), w))\n",
    "\n",
    "def err_rate(labels, predict):\n",
    "    \"\"\"\n",
    "    计算训练样本上的错误率\n",
    "    input:  labels(mat):训练样本的标签\n",
    "            predict(mat):训练样本的预测值\n",
    "    output: rate[0,0](float):错误率\n",
    "    \"\"\"\n",
    "    n_sample, _ = shape(labels)\n",
    "    for j in range(n_sample):\n",
    "        if predict[j,0] > 0.5:\n",
    "            predict[j,0] = 1.0\n",
    "        else:\n",
    "            predict[j,0] = 0.0\n",
    "\n",
    "    err = 0.0\n",
    "    for i in range(n_sample):\n",
    "        if float(label[i, 0]) != float(predict[i, 0]):\n",
    "            err += 1\n",
    "    rate = err / m\n",
    "    return rate\n",
    "\n",
    "def save_model_result(center, rbf_delta, w, result):\n",
    "    \"\"\"\n",
    "    保存最终的模型\n",
    "    \"\"\"\n",
    "    def write_file(file_name, source):   \n",
    "        f = open(file_name, \"w\")\n",
    "        m, n = shape(source)\n",
    "        for i in range(m):\n",
    "            tmp = []\n",
    "            for j in range(n):\n",
    "                tmp.append(str(source[i, j]))\n",
    "            f.write(\"\\t\".join(tmp) + \"\\n\")\n",
    "        f.close()\n",
    "    \n",
    "    write_file(\"center.txt\", center)\n",
    "    write_file(\"delta.txt\", delta)\n",
    "    write_file(\"weight.txt\", w)\n",
    "    write_file('train_result.txt',result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 1. load data ---------\n",
      "--------- 2.training ------------\n",
      "\t-------- iter:  0  ,cost:  11409.183086026864\n",
      "\t-------- iter:  10  ,cost:  2.550120420553891e+46\n",
      "\t-------- iter:  20  ,cost:  1.2616060515459246e+87\n",
      "\t-------- iter:  30  ,cost:  4.0371293934046604e+125\n",
      "\t-------- iter:  40  ,cost:  8.587554180485625e+159\n",
      "\t-------- iter:  50  ,cost:  1.8503358529029686e+196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-------- iter:  60  ,cost:  nan\n",
      "\t-------- iter:  70  ,cost:  nan\n",
      "\t-------- iter:  80  ,cost:  nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-216-637ba257a155>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 2. 训练网络模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"--------- 2.training ------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrbf_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbp_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxIteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.08\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# 3. 得到最终的预测结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"--------- 3.get prediction ------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-214-cd98f8f3f64e>\u001b[0m in \u001b[0;36mbp_train\u001b[1;34m(samples, labels, n_hidden, maxIteration, alpha, n_output)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# 2.2 反向传播\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mbp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrbf_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 传的是引用(传可变对象进去, 就是传引用)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-213-69d960a74ded>\u001b[0m in \u001b[0;36mbp\u001b[1;34m(samples, label, predict, center, rbf_delta, w, alpha)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0msum1\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcenter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcenter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrbf_delta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrbf_delta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcenter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0msum2\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcenter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcenter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrbf_delta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrbf_delta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcenter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcenter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0msum3\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcenter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcenter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrbf_delta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrbf_delta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# 得梯度\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;31m# This promotes 1-D vectors to row vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__rmul__'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1. 导入数据\n",
    "print(\"--------- 1. load data ---------\")\n",
    "samples, labels, n_class = load_data(\"data.txt\")\n",
    "# 2. 训练网络模型\n",
    "print (\"--------- 2.training ------------\")\n",
    "center, rbf_delta, w = bp_train(samples, labels, n_hidden=20, maxIteration=5000, alpha=0.08, n_output=n_class)\n",
    "# 3. 得到最终的预测结果\n",
    "print (\"--------- 3.get prediction ------------\")\n",
    "print (\"训练准确性为：\", (1 - err_rate(labels, get_predict(samples, center, rbf_delta, w))))\n",
    "# 4. 保存最终的模型\n",
    "print (\"--------- 4.save model and result ------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "samples, labels, n_class = load_data(\"data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0:199,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(samples[0:200,0], samples[0:200,1], '+')\n",
    "plt.plot(samples[200:400,0], samples[200:400,1], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1028 02:23:16.551109 17556 deprecation.py:323] From c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------1.Load Data---------------------\n",
      "------------------------2.parameter setting-------------\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(1, 20), b.shape=(20, 2), m=1, n=2, k=20\n\t [[node MatMul (defined at <ipython-input-217-0f2f024f8d3a>:70) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node MatMul:\n Exp (defined at <ipython-input-217-0f2f024f8d3a>:68)\t\n W/read (defined at <ipython-input-217-0f2f024f8d3a>:58)\n\nOriginal stack trace for 'MatMul':\n  File \"c:\\program files\\python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\program files\\python37\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\program files\\python37\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\program files\\python37\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\program files\\python37\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"c:\\program files\\python37\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"c:\\program files\\python37\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"c:\\program files\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\program files\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\program files\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\program files\\python37\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\program files\\python37\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\program files\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\program files\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"c:\\program files\\python37\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\program files\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\program files\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\program files\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-217-0f2f024f8d3a>\", line 132, in <module>\n    rbf.fit()\n  File \"<ipython-input-217-0f2f024f8d3a>\", line 70, in fit\n    output_in = tf.matmul(RBF_OUT,W) + b\n  File \"c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2647, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 6295, in mat_mul\n    name=name)\n  File \"c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(1, 20), b.shape=(20, 2), m=1, n=2, k=20\n\t [[{{node MatMul}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-217-0f2f024f8d3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0minput_data_trainY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[0mrbf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRBF_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_data_trainX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_data_trainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mrbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-217-0f2f024f8d3a>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                     \u001b[0mfeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10.0\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1368\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(1, 20), b.shape=(20, 2), m=1, n=2, k=20\n\t [[node MatMul (defined at <ipython-input-217-0f2f024f8d3a>:70) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node MatMul:\n Exp (defined at <ipython-input-217-0f2f024f8d3a>:68)\t\n W/read (defined at <ipython-input-217-0f2f024f8d3a>:58)\n\nOriginal stack trace for 'MatMul':\n  File \"c:\\program files\\python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\program files\\python37\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\program files\\python37\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\program files\\python37\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\program files\\python37\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"c:\\program files\\python37\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"c:\\program files\\python37\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"c:\\program files\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\program files\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\program files\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\program files\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\program files\\python37\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\program files\\python37\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\program files\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\program files\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"c:\\program files\\python37\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\program files\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\program files\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\program files\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-217-0f2f024f8d3a>\", line 132, in <module>\n    rbf.fit()\n  File \"<ipython-input-217-0f2f024f8d3a>\", line 70, in fit\n    output_in = tf.matmul(RBF_OUT,W) + b\n  File \"c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2647, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 6295, in mat_mul\n    name=name)\n  File \"c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"c:\\program files\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Dec 10 12:48:22 2018\n",
    "@author: lj\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def load_data(file_name):\n",
    "    '''导入数据\n",
    "    input:  file_name(string):文件的存储位置\n",
    "    output: feature_data(mat):特征\n",
    "            label_data(mat):标签\n",
    "            n_class(int):类别的个数\n",
    "    '''\n",
    "    # 1、获取特征\n",
    "    f = open(file_name)  # 打开文件\n",
    "    feature_data = []\n",
    "    label_tmp = []\n",
    "    for line in f.readlines():\n",
    "        feature_tmp = []\n",
    "        lines = line.strip().split(\"\\t\")\n",
    "        for i in range(len(lines) - 1):\n",
    "            feature_tmp.append(float(lines[i]))\n",
    "        label_tmp.append(int(lines[-1]))      \n",
    "        feature_data.append(feature_tmp)\n",
    "    f.close()  # 关闭文件\n",
    "    \n",
    "    # 2、获取标签\n",
    "    m = len(label_tmp)\n",
    "    n_class = len(set(label_tmp))  # 得到类别的个数\n",
    "    \n",
    "    label_data = np.mat(np.zeros((m, n_class)))\n",
    "    for i in range(m):\n",
    "        label_data[i, label_tmp[i]] = 1\n",
    "    \n",
    "    return np.mat(feature_data), label_data\n",
    "\n",
    "class RBF_NN():\n",
    "    def __init__(self,hidden_nodes,input_data_trainX,input_data_trainY):\n",
    "        self.hidden_nodes = hidden_nodes #隐含层节点数\n",
    "        self.input_data_trainX = input_data_trainX #训练样本的特征\n",
    "        self.input_data_trainY = input_data_trainY #训练样本的标签\n",
    "    \n",
    "    def fit(self):\n",
    "        '''模型训练\n",
    "        '''\n",
    "        # 1.声明输入输出的占位符\n",
    "        n_input = (self.input_data_trainX).shape[1]\n",
    "        n_output = (self.input_data_trainY).shape[1]\n",
    "        X = tf.placeholder('float',[None,n_input],name = 'X')\n",
    "        Y = tf.placeholder('float',[None,n_output],name = 'Y')\n",
    "        # 2.参数设置\n",
    "        ## RBF函数参数\n",
    "        c = tf.Variable(tf.random_normal([self.hidden_nodes,n_input]),name = 'c')\n",
    "        delta = tf.Variable(tf.random_normal([1,self.hidden_nodes]),name = 'delta')\n",
    "        ## 隐含层到输出层权重和偏置\n",
    "        W = tf.Variable(tf.random_normal([self.hidden_nodes,n_output]),name = 'W')\n",
    "        b = tf.Variable(tf.random_normal([1,n_output]),name = 'b')\n",
    "        # 3.构造前向传播计算图\n",
    "        ## 隐含层输出\n",
    "        ### 特征样本与RBF均值的距离\n",
    "        dist = tf.reduce_sum(tf.square(tf.subtract(tf.tile(X,[self.hidden_nodes,1]),c)),1)  \n",
    "        dist = tf.multiply(1.0,tf.transpose(dist))\n",
    "        ### RBF方差的平方\n",
    "        delta_2 = tf.square(delta)\n",
    "        ### 隐含层输出\n",
    "        RBF_OUT = tf.exp(tf.multiply(-1.0,tf.divide(dist,tf.multiply(2.0,delta_2))))           \n",
    "        ## 输出层输入\n",
    "        output_in = tf.matmul(RBF_OUT,W) + b\n",
    "        ## 输出层输出\n",
    "        y_pred = tf.nn.sigmoid(output_in)\n",
    "        # 4.声明代价函数优化算法\n",
    "        cost = tf.reduce_mean(tf.pow(Y - y_pred,2)) #损失函数为均方误差\n",
    "        train_op = tf.train.GradientDescentOptimizer(0.05).minimize(cost) #优化算法为梯度下降法\n",
    "        \n",
    "        # 5.反向传播求参数\n",
    "        trX = self.input_data_trainX\n",
    "        trY = self.input_data_trainY\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            ##初始化所有参数\n",
    "            tf.global_variables_initializer().run()\n",
    "            for epoch in range(100):\n",
    "                for i in range(len(trX)):\n",
    "                    feed = {X:trX[i],Y:trY[i]}\n",
    "                    sess.run(train_op,feed_dict = feed)\n",
    "                if epoch % 10.0 == 0:\n",
    "                    total_loss = 0.0\n",
    "                    for j in range(len(trX)):\n",
    "                        total_loss += sess.run(cost,feed_dict = {X:trX[j],Y:trY[j]})\n",
    "                    print('Loss function at step %d is %s'%(epoch,total_loss / len(trX)))\n",
    "            print('Training complete!')\n",
    "\n",
    "            W = W.eval()\n",
    "            b = b.eval()\n",
    "            c = c.eval()\n",
    "            delta = delta.eval()\n",
    "            pred_trX = np.mat(np.zeros((len(trX),n_output)))\n",
    "            ## 训练准确率\n",
    "            correct_tr = 0.0\n",
    "            for i in range(len(trX)):\n",
    "                pred_tr = sess.run(y_pred,feed_dict = {X:trX[i]})\n",
    "                pred_trX[i,:] = pred_tr\n",
    "                if np.argmax(pred_tr,1) == np.argmax(trY[i],1):\n",
    "                    correct_tr += 1.0\n",
    "            print('Accuracy on train set is :%s'%(correct_tr/len(trX)))\n",
    "            self.save_model('RBF_predict_results.txt',pred_trX)\n",
    "            \n",
    "    def save_model(self,file_name,weights):\n",
    "        '''保存模型(保存权重weights)\n",
    "        input：file_name(string):文件名\n",
    "               weights(mat)：权重矩阵\n",
    "        '''\n",
    "        f_w = open(file_name,'w')\n",
    "        m,n = np.shape(weights)\n",
    "        for i in range(m):\n",
    "            w_tmp = []\n",
    "            for j in range(n):\n",
    "                w_tmp.append(str(weights[i,j]))\n",
    "            f_w.write('\\t'.join(w_tmp)+'\\n')\n",
    "        f_w.close()\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    print('------------------------1.Load Data---------------------')\n",
    "    trainX, trainY = load_data('data.txt')\n",
    "    print('------------------------2.parameter setting-------------')\n",
    "    hidden_nodes = 20\n",
    "    input_data_trainX = trainX\n",
    "    input_data_trainY = trainY\n",
    "    rbf = RBF_NN(hidden_nodes,input_data_trainX,input_data_trainY)\n",
    "    rbf.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
